# Training Neural Networks

0. Prepare and understand Datasets



1. Neural network architecture

input and output

common layers:

model complexity

2. Activation functions
    Sigmoid
    tanh
    ReLU
    Leaky ReLU
    Maxout
    Elu
    
3. Weight initialization
    gradiant valishing or exploration

4. Data preprocessing -- make optimization easier
    Standardlization
    normalization
    
5. Batch Normalization -- performance depends on mini-batch

6. Baby sitting model learning
    traing_loss/val_loss
    Accuracy
    
    using tensorboard
    
    overfiting / underfitting
    
7. Hyperparameter search
    grid search
    random search

    Learning rate is the most important
    




