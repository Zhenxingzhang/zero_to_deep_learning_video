{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw CIFAR-10 data\n",
    "train_ds, test_ds = tfds.load(\"cifar10\",\n",
    "                              split=[tfds.Split.TRAIN, tfds.Split.TEST],\n",
    "                              batch_size=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_ds[\"image\"]\n",
    "test_images = test_ds[\"image\"]\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "train_labels = train_ds[\"label\"]\n",
    "test_labels = test_ds[\"label\"]\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images[0].numpy().min())\n",
    "train_images[0].numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.dtypes.cast(train_images, tf.float32)#.astype('float32')\n",
    "x_test = tf.dtypes.cast(test_images, tf.float32)\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print(type(x_train))\n",
    "print(x_train[0].numpy().min())\n",
    "print(x_train[0].numpy().max())\n",
    "\n",
    "print(type(x_test))\n",
    "print(x_test[0].numpy().min())\n",
    "print(x_test[0].numpy().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the use of batch normalization\n",
    "# https://machinelearningmastery.com/how-to-accelerate-learning-of-deep-neural-networks-with-batch-normalization/\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(32, 32,3)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation= \"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from here https://keras.io/examples/cifar10_cnn/\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "cnn_model = keras.Sequential([\n",
    "    Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=train_images.shape[1:]),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(32, (3, 3)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(64, (3, 3)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512),\n",
    "    BatchNormalization(),\n",
    "    Dense(10),\n",
    "    BatchNormalization(),\n",
    "    Activation('softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.001, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "\n",
    "cnn_model.compile(optimizer=sgd,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10\n",
    "EPOCHS = 200\n",
    "TENSORBOARD_LOGDIR = \"../tensorboard/cifar-10/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model-{val_accuracy:.2f}.h5\", monitor=\"val_accuracy\", verbose=1, save_best_only=True,\n",
    "                             save_weights_only=True, mode=\"max\")\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, mode=\"min\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=PATIENCE, min_lr=1e-7, verbose=1, mode=\"min\")\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=TENSORBOARD_LOGDIR)\n",
    "cnn_model.fit(x_train, train_labels,\n",
    "              validation_data=(x_test, test_labels),\n",
    "              callbacks=[checkpoint, reduce_lr, early_stop, tensorboard_callback],\n",
    "              epochs=EPOCHS,\n",
    "              verbose=0,\n",
    "              shuffle=True,\n",
    "              batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score trained model.\n",
    "scores = cnn_model.evaluate(x_test, test_labels, verbose=0)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix result, \n",
    "# code from here: https://ermlab.com/en/blog/nlp/cifar-10-classification-using-keras-tutorial/\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = cnn_model.predict(x_test, verbose=2)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "for ix in range(10):\n",
    "    print(ix, confusion_matrix(test_labels,y_pred)[ix].sum())\n",
    "cm = confusion_matrix(test_labels,y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Visualizing of confusion matrix\n",
    "import seaborn as sn\n",
    "import pandas  as pd\n",
    "\n",
    "df_cm = pd.DataFrame(cm, range(10),\n",
    "                  range(10))\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 12})# font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from here https://www.tensorflow.org/tutorials/keras/basic_classification\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, Y_pred, test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, Y_pred,  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted label, and the true label\n",
    "# Color correct predictions in blue, incorrect predictions in red\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, Y_pred, test_labels, test_images)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(i, Y_pred, test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
